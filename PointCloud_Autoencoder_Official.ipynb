{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOuwgnCjKPgHHgeQBepoPYd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/horaja/PointCloudAutoEncoder/blob/main/PointCloud_Autoencoder_Official.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "The following codeblock is for library imports.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "t0HnlI4zy1ko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DnLeHAh6xIIT"
      },
      "outputs": [],
      "source": [
        "import Dataloaders\n",
        "import utils\n",
        "import model\n",
        "\n",
        "import torch\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Next, we must configure necessary parameters:\n",
        " - batch size\n",
        " - name of output folder to save results\n",
        " - save results enable/disable flag\n",
        " - GPU acceleration flag\n",
        " - dimension of compressed representation\n",
        "```"
      ],
      "metadata": {
        "id": "XFBeWCoKzIIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "output_folder = \"output/\"\n",
        "save_results = False\n",
        "use_GPU = True\n",
        "latent_size = 128\n",
        "\n",
        "if(save_results):\n",
        "    utils.clear_folder(output_folder)"
      ],
      "metadata": {
        "id": "TPoYOPZSzkSQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Next, we must load in our data properly\n",
        "\n",
        "We must also condense thousands of pointcloud snapshots into one file.\n",
        "\n",
        "Factors to influence:\n",
        " - # of snapshots\n",
        " - # of points per snapshot\n",
        " - area to extract points for each snapshot (ranges)\n",
        "```"
      ],
      "metadata": {
        "id": "evqn9Gmp1CRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = \"/content/input_data\"\n",
        "\n",
        "combined_data = Dataloaders.CondensePointClouds(input_folder, 1024)\n",
        "pc_array = combined_data\n",
        "print(pc_array.shape) # for testing purposes\n",
        "\n",
        "train_loader, test_loader = Dataloaders.GetDataLoaders(npArray=pc_array, batch_size=batch_size)\n",
        "print(f\"Train dataset size: {len(train_loader.dataset)}\") # for testing purposes\n",
        "print(f\"Test dataset size: {len(test_loader.dataset)}\") # for testing purposes\n",
        "print(f\"Batch size: {batch_size}\") # for testing purposes\n",
        "\n",
        "point_size = len(train_loader.dataset[0])"
      ],
      "metadata": {
        "id": "tPpVxDAL1r5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Model Setup\n",
        "```"
      ],
      "metadata": {
        "id": "WLG-T_6pDG3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = model.PointCloudAE(point_size,latent_size)\n",
        "\n",
        "if(use_GPU):\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    if torch.cuda.device_count() > 1: # if there are multiple GPUs use all\n",
        "        net = torch.nn.DataParallel(net)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "fAIEwnobDKCT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Import and initialize loss (chamfer distance)\n",
        "Define an optimizer\n",
        "```"
      ],
      "metadata": {
        "id": "3V6-CDkdDnnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chamferdist\n",
        "from chamferdist import ChamferDistance\n",
        "chamfer_distance = ChamferDistance()\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0005)"
      ],
      "metadata": {
        "id": "rs08puPKDs87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Next, we must define training and testing functions\n",
        "```"
      ],
      "metadata": {
        "id": "H5wrpYbeD-gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch():\n",
        "    epoch_loss = 0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = net(data.permute(0,2,1))\n",
        "        loss = chamfer_distance(data, output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/i"
      ],
      "metadata": {
        "id": "QviGexvcED8H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_batch(data):\n",
        "    with torch.no_grad():\n",
        "        output = net(data.permute(0,2,1))\n",
        "        loss = chamfer_distance(data, output)\n",
        "\n",
        "    return loss.item(), output.cpu()"
      ],
      "metadata": {
        "id": "C43qh85BFRND"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_epoch():\n",
        "    with torch.no_grad():\n",
        "        epoch_loss = 0\n",
        "        for i, data in enumerate(test_loader):\n",
        "            loss, output = test_batch(data)\n",
        "            epoch_loss += loss\n",
        "\n",
        "    if i != 0:\n",
        "      return epoch_loss/i\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "8nbj-Qt4E4GS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Training Loop\n",
        "\n",
        "Be sure to edit the number of epochs!\n",
        "```"
      ],
      "metadata": {
        "id": "G2Cv6HwrFKfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "for i in range(1) :\n",
        "\n",
        "    startTime = time.time()\n",
        "    train_loss = train_epoch()\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    test_loss = test_epoch()\n",
        "    test_loss_list.append(test_loss)\n",
        "\n",
        "    epoch_time = time.time() - startTime\n",
        "\n",
        "    writeString = \"epoch \" + str(i) + \" train loss : \" + str(train_loss) + \" test loss : \" + str(test_loss) + \" epoch time : \" + str(epoch_time) + \"\\n\"\n",
        "\n",
        "    plt.plot(train_loss_list, label=\"Train\")\n",
        "    plt.plot(test_loss_list, label=\"Test\")\n",
        "    plt.legend()\n",
        "\n",
        "    if (save_results):\n",
        "        with open(output_folder + \"prints.txt\",\"a\") as file:\n",
        "            file.write(writeString)\n",
        "\n",
        "        plt.savefig(output_folder + \"loss.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # FIX: save all these to output folder, not just show them.\n",
        "        if(i%50==0):\n",
        "            test_samples = next(iter(test_loader))\n",
        "            loss , test_output = test_batch(test_samples)\n",
        "            utils.visualise_3(test_output[i], output_file= (output_folder  + \"epoch_\" + str(i)))\n",
        "\n",
        "    else:\n",
        "        print(writeString)\n",
        "        test_samples = next(iter(test_loader))\n",
        "        loss , test_output = test_batch(test_samples)\n",
        "        index = i % len(test_output)\n",
        "        utils.visualise_3(test_output[index])\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "F-xGzZjtFMkm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}